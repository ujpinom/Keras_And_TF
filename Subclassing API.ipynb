{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wideandeepmodel(keras.models.Model):\n",
    "\n",
    "    def __init__(self,units=30,activacion='relu',**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.hidden1= keras.layers.Dense(units=units,activation=activacion)\n",
    "        self.hidden2=keras.layers.Dense(units=units,activation=activacion)\n",
    "        self.main_ouput=keras.layers.Dense(1)\n",
    "        self.aux_ouput=keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        input_a,input_b=inputs\n",
    "        h1=self.hidden1(input_b)\n",
    "        h2=self.hidden2(h1)\n",
    "        conca=keras.layers.concatenate([input_a,h2])\n",
    "        main_output=self.main_ouput(conca)\n",
    "        aux_output=self.aux_ouput(h2)\n",
    "\n",
    "        return main_output,aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing;from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X,y= fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=wideandeepmodel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(loss='mean_squared_error',optimizer=keras.optimizers.SGD(1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 4.5433 - output_1_loss: 2.0259 - output_2_loss: 2.5175 - val_loss: 2.0444 - val_output_1_loss: 0.7885 - val_output_2_loss: 1.2559\n",
      "Epoch 2/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.7977 - output_1_loss: 0.6840 - output_2_loss: 1.1137 - val_loss: 1.7258 - val_output_1_loss: 0.6700 - val_output_2_loss: 1.0558\n",
      "Epoch 3/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.5808 - output_1_loss: 0.6172 - output_2_loss: 0.9636 - val_loss: 1.5663 - val_output_1_loss: 0.6317 - val_output_2_loss: 0.9346\n",
      "Epoch 4/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.4561 - output_1_loss: 0.5861 - output_2_loss: 0.8701 - val_loss: 1.4614 - val_output_1_loss: 0.6046 - val_output_2_loss: 0.8568\n",
      "Epoch 5/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.3697 - output_1_loss: 0.5607 - output_2_loss: 0.8090 - val_loss: 1.3863 - val_output_1_loss: 0.5823 - val_output_2_loss: 0.8040\n",
      "Epoch 6/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.3087 - output_1_loss: 0.5408 - output_2_loss: 0.7679 - val_loss: 1.3346 - val_output_1_loss: 0.5633 - val_output_2_loss: 0.7714\n",
      "Epoch 7/20\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 1.2652 - output_1_loss: 0.5232 - output_2_loss: 0.7420 - val_loss: 1.2990 - val_output_1_loss: 0.5484 - val_output_2_loss: 0.7506\n",
      "Epoch 8/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.2306 - output_1_loss: 0.5098 - output_2_loss: 0.7207 - val_loss: 1.2696 - val_output_1_loss: 0.5360 - val_output_2_loss: 0.7336\n",
      "Epoch 9/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.2065 - output_1_loss: 0.4988 - output_2_loss: 0.7077 - val_loss: 1.2490 - val_output_1_loss: 0.5259 - val_output_2_loss: 0.7231\n",
      "Epoch 10/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.1846 - output_1_loss: 0.4891 - output_2_loss: 0.6956 - val_loss: 1.2317 - val_output_1_loss: 0.5178 - val_output_2_loss: 0.7140\n",
      "Epoch 11/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.1671 - output_1_loss: 0.4811 - output_2_loss: 0.6860 - val_loss: 1.2182 - val_output_1_loss: 0.5120 - val_output_2_loss: 0.7062\n",
      "Epoch 12/20\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 1.1507 - output_1_loss: 0.4741 - output_2_loss: 0.6766 - val_loss: 1.2061 - val_output_1_loss: 0.5066 - val_output_2_loss: 0.6995\n",
      "Epoch 13/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.1377 - output_1_loss: 0.4683 - output_2_loss: 0.6694 - val_loss: 1.1923 - val_output_1_loss: 0.5000 - val_output_2_loss: 0.6923\n",
      "Epoch 14/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.1241 - output_1_loss: 0.4628 - output_2_loss: 0.6612 - val_loss: 1.1827 - val_output_1_loss: 0.4965 - val_output_2_loss: 0.6862\n",
      "Epoch 15/20\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 1.1124 - output_1_loss: 0.4583 - output_2_loss: 0.6541 - val_loss: 1.1732 - val_output_1_loss: 0.4926 - val_output_2_loss: 0.6806\n",
      "Epoch 16/20\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 1.1014 - output_1_loss: 0.4536 - output_2_loss: 0.6478 - val_loss: 1.1654 - val_output_1_loss: 0.4878 - val_output_2_loss: 0.6776\n",
      "Epoch 17/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.0915 - output_1_loss: 0.4503 - output_2_loss: 0.6412 - val_loss: 1.1546 - val_output_1_loss: 0.4857 - val_output_2_loss: 0.6689\n",
      "Epoch 18/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.0828 - output_1_loss: 0.4469 - output_2_loss: 0.6359 - val_loss: 1.1434 - val_output_1_loss: 0.4813 - val_output_2_loss: 0.6621\n",
      "Epoch 19/20\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.0734 - output_1_loss: 0.4438 - output_2_loss: 0.6295 - val_loss: 1.1341 - val_output_1_loss: 0.4779 - val_output_2_loss: 0.6562\n",
      "Epoch 20/20\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 1.0641 - output_1_loss: 0.4407 - output_2_loss: 0.6235 - val_loss: 1.1296 - val_output_1_loss: 0.4768 - val_output_2_loss: 0.6528\n"
     ]
    }
   ],
   "source": [
    "hist=modelo.fit(x=[X_train_A,X_train_B],y=[y_train,y_train],validation_split=0.2,epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1,y_pred2=modelo.predict([X_test_A,X_test_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6626286694073888"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5468959631840093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 2.0501 - val_loss: 0.8718\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 0s 939us/step - loss: 0.7599 - val_loss: 0.7209\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 0s 929us/step - loss: 0.6775 - val_loss: 0.6802\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 0s 934us/step - loss: 0.6398 - val_loss: 0.6493\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 0s 920us/step - loss: 0.6105 - val_loss: 0.6236\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.5867 - val_loss: 0.6021\n",
      "Epoch 7/100\n",
      "387/387 [==============================] - 0s 901us/step - loss: 0.5669 - val_loss: 0.5842\n",
      "Epoch 8/100\n",
      "387/387 [==============================] - 0s 925us/step - loss: 0.5502 - val_loss: 0.5701\n",
      "Epoch 9/100\n",
      "387/387 [==============================] - 0s 909us/step - loss: 0.5362 - val_loss: 0.5576\n",
      "Epoch 10/100\n",
      "387/387 [==============================] - 0s 935us/step - loss: 0.5243 - val_loss: 0.5470\n",
      "Epoch 11/100\n",
      "387/387 [==============================] - 0s 961us/step - loss: 0.5140 - val_loss: 0.5389\n",
      "Epoch 12/100\n",
      "387/387 [==============================] - 0s 905us/step - loss: 0.5057 - val_loss: 0.5308\n",
      "Epoch 13/100\n",
      "387/387 [==============================] - 0s 997us/step - loss: 0.4981 - val_loss: 0.5241\n",
      "Epoch 14/100\n",
      "387/387 [==============================] - 0s 900us/step - loss: 0.4916 - val_loss: 0.5182\n",
      "Epoch 15/100\n",
      "387/387 [==============================] - 0s 907us/step - loss: 0.4857 - val_loss: 0.5124\n",
      "Epoch 16/100\n",
      "387/387 [==============================] - 0s 947us/step - loss: 0.4803 - val_loss: 0.5077\n",
      "Epoch 17/100\n",
      "387/387 [==============================] - 0s 944us/step - loss: 0.4754 - val_loss: 0.5040\n",
      "Epoch 18/100\n",
      "387/387 [==============================] - 0s 956us/step - loss: 0.4711 - val_loss: 0.5000\n",
      "Epoch 19/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4964\n",
      "Epoch 20/100\n",
      "387/387 [==============================] - 0s 929us/step - loss: 0.4636 - val_loss: 0.4933\n",
      "Epoch 21/100\n",
      "387/387 [==============================] - 0s 917us/step - loss: 0.4601 - val_loss: 0.4910\n",
      "Epoch 22/100\n",
      "387/387 [==============================] - 0s 992us/step - loss: 0.4571 - val_loss: 0.4879\n",
      "Epoch 23/100\n",
      "387/387 [==============================] - 0s 991us/step - loss: 0.4545 - val_loss: 0.4851\n",
      "Epoch 24/100\n",
      "387/387 [==============================] - 0s 990us/step - loss: 0.4519 - val_loss: 0.4829\n",
      "Epoch 25/100\n",
      "387/387 [==============================] - 0s 960us/step - loss: 0.4495 - val_loss: 0.4802\n",
      "Epoch 26/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4776\n",
      "Epoch 27/100\n",
      "387/387 [==============================] - 0s 945us/step - loss: 0.4452 - val_loss: 0.4765\n",
      "Epoch 28/100\n",
      "387/387 [==============================] - 0s 941us/step - loss: 0.4432 - val_loss: 0.4747\n",
      "Epoch 29/100\n",
      "387/387 [==============================] - 0s 954us/step - loss: 0.4414 - val_loss: 0.4728\n",
      "Epoch 30/100\n",
      "387/387 [==============================] - 0s 988us/step - loss: 0.4397 - val_loss: 0.4717\n",
      "Epoch 31/100\n",
      "387/387 [==============================] - 0s 987us/step - loss: 0.4380 - val_loss: 0.4698\n",
      "Epoch 32/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4691\n",
      "Epoch 33/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4671\n",
      "Epoch 34/100\n",
      "387/387 [==============================] - 0s 896us/step - loss: 0.4335 - val_loss: 0.4658\n",
      "Epoch 35/100\n",
      "387/387 [==============================] - 0s 961us/step - loss: 0.4322 - val_loss: 0.4647\n",
      "Epoch 36/100\n",
      "387/387 [==============================] - 0s 947us/step - loss: 0.4309 - val_loss: 0.4635\n",
      "Epoch 37/100\n",
      "387/387 [==============================] - 0s 944us/step - loss: 0.4297 - val_loss: 0.4620\n",
      "Epoch 38/100\n",
      "387/387 [==============================] - 0s 932us/step - loss: 0.4284 - val_loss: 0.4608\n",
      "Epoch 39/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4597\n",
      "Epoch 40/100\n",
      "387/387 [==============================] - 0s 901us/step - loss: 0.4261 - val_loss: 0.4586\n",
      "Epoch 41/100\n",
      "387/387 [==============================] - 0s 907us/step - loss: 0.4250 - val_loss: 0.4574\n",
      "Epoch 42/100\n",
      "387/387 [==============================] - 0s 955us/step - loss: 0.4238 - val_loss: 0.4570\n",
      "Epoch 43/100\n",
      "387/387 [==============================] - 0s 982us/step - loss: 0.4230 - val_loss: 0.4555\n",
      "Epoch 44/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4546\n",
      "Epoch 45/100\n",
      "387/387 [==============================] - 0s 952us/step - loss: 0.4209 - val_loss: 0.4540\n",
      "Epoch 46/100\n",
      "387/387 [==============================] - 0s 990us/step - loss: 0.4200 - val_loss: 0.4530\n",
      "Epoch 47/100\n",
      "387/387 [==============================] - 0s 956us/step - loss: 0.4191 - val_loss: 0.4518\n",
      "Epoch 48/100\n",
      "387/387 [==============================] - 0s 952us/step - loss: 0.4181 - val_loss: 0.4514\n",
      "Epoch 49/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4509\n",
      "Epoch 50/100\n",
      "387/387 [==============================] - 0s 993us/step - loss: 0.4164 - val_loss: 0.4494\n",
      "Epoch 51/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4489\n",
      "Epoch 52/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4478\n",
      "Epoch 53/100\n",
      "387/387 [==============================] - 0s 944us/step - loss: 0.4138 - val_loss: 0.4471\n",
      "Epoch 54/100\n",
      "387/387 [==============================] - 0s 974us/step - loss: 0.4130 - val_loss: 0.4462\n",
      "Epoch 55/100\n",
      "387/387 [==============================] - 0s 996us/step - loss: 0.4122 - val_loss: 0.4453\n",
      "Epoch 56/100\n",
      "387/387 [==============================] - 0s 914us/step - loss: 0.4115 - val_loss: 0.4451\n",
      "Epoch 57/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4443\n",
      "Epoch 58/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4436\n",
      "Epoch 59/100\n",
      "387/387 [==============================] - 0s 944us/step - loss: 0.4092 - val_loss: 0.4427\n",
      "Epoch 60/100\n",
      "387/387 [==============================] - 0s 934us/step - loss: 0.4084 - val_loss: 0.4424\n",
      "Epoch 61/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4415\n",
      "Epoch 62/100\n",
      "387/387 [==============================] - 0s 923us/step - loss: 0.4070 - val_loss: 0.4407\n",
      "Epoch 63/100\n",
      "387/387 [==============================] - 0s 955us/step - loss: 0.4063 - val_loss: 0.4401\n",
      "Epoch 64/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.4396\n",
      "Epoch 65/100\n",
      "387/387 [==============================] - 0s 926us/step - loss: 0.4049 - val_loss: 0.4391\n",
      "Epoch 66/100\n",
      "387/387 [==============================] - 0s 988us/step - loss: 0.4043 - val_loss: 0.4384\n",
      "Epoch 67/100\n",
      "387/387 [==============================] - 0s 945us/step - loss: 0.4036 - val_loss: 0.4377\n",
      "Epoch 68/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4371\n",
      "Epoch 69/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4364\n",
      "Epoch 70/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.4362\n",
      "Epoch 71/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4353\n",
      "Epoch 72/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4347\n",
      "Epoch 73/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4350\n",
      "Epoch 74/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.4340\n",
      "Epoch 75/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4338\n",
      "Epoch 76/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4328\n",
      "Epoch 77/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4326\n",
      "Epoch 78/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4325\n",
      "Epoch 79/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4312\n",
      "Epoch 80/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4307\n",
      "Epoch 81/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4301\n",
      "Epoch 82/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4297\n",
      "Epoch 83/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4298\n",
      "Epoch 84/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4289\n",
      "Epoch 85/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4288\n",
      "Epoch 86/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4279\n",
      "Epoch 87/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4277\n",
      "Epoch 88/100\n",
      "387/387 [==============================] - 0s 914us/step - loss: 0.3918 - val_loss: 0.4269\n",
      "Epoch 89/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4267\n",
      "Epoch 90/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4261\n",
      "Epoch 91/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.4260\n",
      "Epoch 92/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4252\n",
      "Epoch 93/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.4251\n",
      "Epoch 94/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.4243\n",
      "Epoch 95/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.4240\n",
      "Epoch 96/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.4237\n",
      "Epoch 97/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.4232\n",
      "Epoch 98/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4228\n",
      "Epoch 99/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4223\n",
      "Epoch 100/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.4220\n"
     ]
    }
   ],
   "source": [
    "modelo=keras.models.Sequential([keras.layers.Dense(30,activation='relu',\n",
    "                                                   input_shape=[X_train.shape[1]]),\n",
    "                                keras.layers.Dense(1)])\n",
    "\n",
    "modelo.compile(loss='mean_squared_error',optimizer=keras.optimizers.SGD(1e-3))\n",
    "\n",
    "early_stopping= keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "histo= modelo.fit(x=X_train_scaled,y=y_train,validation_split=0.2,epochs=100,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010211105659221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,modelo.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/387 [..............................] - ETA: 0s - loss: 6.1454WARNING:tensorflow:From C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/387 [..............................] - ETA: 53s - loss: 4.6177WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0040s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.2688s). Check your callbacks.\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 2.2206 - val_loss: 1.1596\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.9415 - val_loss: 0.8449\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.7743 - val_loss: 0.7677\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 0s 955us/step - loss: 0.7198 - val_loss: 0.7265\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 0s 974us/step - loss: 0.6843 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 0s 998us/step - loss: 0.6551 - val_loss: 0.6658\n",
      "Epoch 7/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.6296 - val_loss: 0.6428\n",
      "Epoch 8/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.6214\n",
      "Epoch 9/100\n",
      "387/387 [==============================] - 0s 969us/step - loss: 0.5875 - val_loss: 0.6031\n",
      "Epoch 10/100\n",
      "387/387 [==============================] - 0s 996us/step - loss: 0.5700 - val_loss: 0.5860\n",
      "Epoch 11/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.5544 - val_loss: 0.5717\n",
      "Epoch 12/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.5404 - val_loss: 0.5587\n",
      "Epoch 13/100\n",
      "387/387 [==============================] - 0s 992us/step - loss: 0.5283 - val_loss: 0.5477\n",
      "Epoch 14/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5386\n",
      "Epoch 15/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.5298\n",
      "Epoch 16/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 0.5232\n",
      "Epoch 17/100\n",
      "387/387 [==============================] - 0s 995us/step - loss: 0.4938 - val_loss: 0.5172\n",
      "Epoch 18/100\n",
      "387/387 [==============================] - 0s 997us/step - loss: 0.4880 - val_loss: 0.5118\n",
      "Epoch 19/100\n",
      "387/387 [==============================] - 0s 985us/step - loss: 0.4827 - val_loss: 0.5083\n",
      "Epoch 20/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4785 - val_loss: 0.5039\n",
      "Epoch 21/100\n",
      "387/387 [==============================] - 0s 998us/step - loss: 0.4747 - val_loss: 0.5004\n",
      "Epoch 22/100\n",
      "387/387 [==============================] - 0s 943us/step - loss: 0.4713 - val_loss: 0.4978\n",
      "Epoch 23/100\n",
      "387/387 [==============================] - 0s 997us/step - loss: 0.4681 - val_loss: 0.4951\n",
      "Epoch 24/100\n",
      "387/387 [==============================] - 0s 997us/step - loss: 0.4654 - val_loss: 0.4929\n",
      "Epoch 25/100\n",
      "387/387 [==============================] - 0s 987us/step - loss: 0.4627 - val_loss: 0.4915\n",
      "Epoch 26/100\n",
      "387/387 [==============================] - 0s 965us/step - loss: 0.4605 - val_loss: 0.4892\n",
      "Epoch 27/100\n",
      "387/387 [==============================] - 0s 998us/step - loss: 0.4583 - val_loss: 0.4869\n",
      "Epoch 28/100\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4563 - val_loss: 0.4859\n",
      "Epoch 29/100\n",
      "387/387 [==============================] - 0s 993us/step - loss: 0.4545 - val_loss: 0.4838\n",
      "Epoch 30/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4822\n",
      "Epoch 31/100\n",
      "387/387 [==============================] - 0s 994us/step - loss: 0.4509 - val_loss: 0.4813\n",
      "Epoch 32/100\n",
      "387/387 [==============================] - 0s 990us/step - loss: 0.4490 - val_loss: 0.4799\n",
      "Epoch 33/100\n",
      "387/387 [==============================] - 0s 994us/step - loss: 0.4477 - val_loss: 0.4788\n",
      "Epoch 34/100\n",
      "387/387 [==============================] - 0s 984us/step - loss: 0.4461 - val_loss: 0.4770\n",
      "Epoch 35/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4446 - val_loss: 0.4760\n",
      "Epoch 36/100\n",
      "387/387 [==============================] - 0s 934us/step - loss: 0.4431 - val_loss: 0.4749\n",
      "Epoch 37/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4741\n",
      "Epoch 38/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4721\n",
      "Epoch 39/100\n",
      "387/387 [==============================] - 0s 990us/step - loss: 0.4393 - val_loss: 0.4717\n",
      "Epoch 40/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4710\n",
      "Epoch 41/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4697\n",
      "Epoch 42/100\n",
      "387/387 [==============================] - 0s 989us/step - loss: 0.4358 - val_loss: 0.4685\n",
      "Epoch 43/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.4673\n",
      "Epoch 44/100\n",
      "387/387 [==============================] - 0s 995us/step - loss: 0.4335 - val_loss: 0.4662\n",
      "Epoch 45/100\n",
      "387/387 [==============================] - 0s 934us/step - loss: 0.4324 - val_loss: 0.4656\n",
      "Epoch 46/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.4647\n",
      "Epoch 47/100\n",
      "387/387 [==============================] - 0s 985us/step - loss: 0.4302 - val_loss: 0.4637\n",
      "Epoch 48/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4637\n",
      "Epoch 49/100\n",
      "387/387 [==============================] - 0s 994us/step - loss: 0.4283 - val_loss: 0.4617\n",
      "Epoch 50/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4613\n",
      "Epoch 51/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4606\n",
      "Epoch 52/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4598\n",
      "Epoch 53/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4590\n",
      "Epoch 54/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4581\n",
      "Epoch 55/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4580\n",
      "Epoch 56/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4220 - val_loss: 0.4565\n",
      "Epoch 57/100\n",
      "387/387 [==============================] - 0s 997us/step - loss: 0.4210 - val_loss: 0.4558\n",
      "Epoch 58/100\n",
      "387/387 [==============================] - 0s 986us/step - loss: 0.4203 - val_loss: 0.4552\n",
      "Epoch 59/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4555\n",
      "Epoch 60/100\n",
      "387/387 [==============================] - 0s 996us/step - loss: 0.4187 - val_loss: 0.4537\n",
      "Epoch 61/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4530\n",
      "Epoch 62/100\n",
      "387/387 [==============================] - 0s 996us/step - loss: 0.4170 - val_loss: 0.4524\n",
      "Epoch 63/100\n",
      "387/387 [==============================] - 0s 954us/step - loss: 0.4161 - val_loss: 0.4515\n",
      "Epoch 64/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4510\n",
      "Epoch 65/100\n",
      "387/387 [==============================] - 0s 993us/step - loss: 0.4146 - val_loss: 0.4500\n",
      "Epoch 66/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4492\n",
      "Epoch 67/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4488\n",
      "Epoch 68/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4479\n",
      "Epoch 69/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4475\n",
      "Epoch 70/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4478\n",
      "Epoch 71/100\n",
      "387/387 [==============================] - 0s 995us/step - loss: 0.4103 - val_loss: 0.4469\n",
      "Epoch 72/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4454\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 995us/step - loss: 0.4086 - val_loss: 0.4452\n",
      "Epoch 74/100\n",
      "387/387 [==============================] - 0s 954us/step - loss: 0.4083 - val_loss: 0.4444\n",
      "Epoch 75/100\n",
      "387/387 [==============================] - 0s 992us/step - loss: 0.4074 - val_loss: 0.4436\n",
      "Epoch 76/100\n",
      "387/387 [==============================] - 0s 945us/step - loss: 0.4068 - val_loss: 0.4431\n",
      "Epoch 77/100\n",
      "387/387 [==============================] - 0s 938us/step - loss: 0.4060 - val_loss: 0.4430\n",
      "Epoch 78/100\n",
      "387/387 [==============================] - 0s 954us/step - loss: 0.4055 - val_loss: 0.4419\n",
      "Epoch 79/100\n",
      "387/387 [==============================] - 0s 942us/step - loss: 0.4047 - val_loss: 0.4414\n",
      "Epoch 80/100\n",
      "387/387 [==============================] - 0s 998us/step - loss: 0.4041 - val_loss: 0.4410\n",
      "Epoch 81/100\n",
      "387/387 [==============================] - 0s 921us/step - loss: 0.4034 - val_loss: 0.4403\n",
      "Epoch 82/100\n",
      "387/387 [==============================] - 0s 955us/step - loss: 0.4028 - val_loss: 0.4395\n",
      "Epoch 83/100\n",
      "387/387 [==============================] - 0s 898us/step - loss: 0.4021 - val_loss: 0.4389\n",
      "Epoch 84/100\n",
      "387/387 [==============================] - 0s 957us/step - loss: 0.4016 - val_loss: 0.4385\n",
      "Epoch 85/100\n",
      "387/387 [==============================] - 0s 993us/step - loss: 0.4009 - val_loss: 0.4378\n",
      "Epoch 86/100\n",
      "387/387 [==============================] - 0s 956us/step - loss: 0.4004 - val_loss: 0.4369\n",
      "Epoch 87/100\n",
      "387/387 [==============================] - 0s 951us/step - loss: 0.3996 - val_loss: 0.4360\n",
      "Epoch 88/100\n",
      "387/387 [==============================] - 0s 982us/step - loss: 0.3991 - val_loss: 0.4356\n",
      "Epoch 89/100\n",
      "387/387 [==============================] - 0s 982us/step - loss: 0.3984 - val_loss: 0.4349\n",
      "Epoch 90/100\n",
      "387/387 [==============================] - 0s 926us/step - loss: 0.3979 - val_loss: 0.4346\n",
      "Epoch 91/100\n",
      "387/387 [==============================] - 0s 931us/step - loss: 0.3973 - val_loss: 0.4339\n",
      "Epoch 92/100\n",
      "387/387 [==============================] - 0s 976us/step - loss: 0.3968 - val_loss: 0.4332\n",
      "Epoch 93/100\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4327\n",
      "Epoch 94/100\n",
      "387/387 [==============================] - 0s 910us/step - loss: 0.3954 - val_loss: 0.4328\n",
      "Epoch 95/100\n",
      "387/387 [==============================] - 0s 953us/step - loss: 0.3948 - val_loss: 0.4323\n",
      "Epoch 96/100\n",
      "387/387 [==============================] - 0s 942us/step - loss: 0.3944 - val_loss: 0.4307\n",
      "Epoch 97/100\n",
      "387/387 [==============================] - 0s 958us/step - loss: 0.3936 - val_loss: 0.4308\n",
      "Epoch 98/100\n",
      "387/387 [==============================] - 0s 997us/step - loss: 0.3932 - val_loss: 0.4301\n",
      "Epoch 99/100\n",
      "387/387 [==============================] - 0s 932us/step - loss: 0.3925 - val_loss: 0.4294\n",
      "Epoch 100/100\n",
      "387/387 [==============================] - 0s 958us/step - loss: 0.3920 - val_loss: 0.4287\n"
     ]
    }
   ],
   "source": [
    "modelo=keras.models.Sequential([keras.layers.Dense(30,activation='relu',\n",
    "                                                   input_shape=[X_train.shape[1]]),\n",
    "                                keras.layers.Dense(1)])\n",
    "\n",
    "modelo.compile(loss='mean_squared_error',optimizer=keras.optimizers.SGD(1e-3))\n",
    "\n",
    "tensorboard= keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "histo= modelo.fit(x=X_train_scaled,y=y_train,validation_split=0.2,epochs=100,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
